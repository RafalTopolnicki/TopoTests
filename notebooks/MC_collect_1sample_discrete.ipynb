{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f28936-3b84-4d7d-8475-027e98ee3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from functools import cmp_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c6a21a3-999f-433f-83eb-7b8c2c8fff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_str2float(x):\n",
    "    return list(map(float, x.replace('[','').replace(']','').split(',')))\n",
    "\n",
    "def accepted_h0(pvals, alpha):\n",
    "    return np.mean(np.array(list_str2float(pvals)) > alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb36f97-99c0-44fe-a2b9-aede44a6a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(item1, item2):\n",
    "    if item1.startswith('N0'):\n",
    "        if item2.startswith('N0'):\n",
    "            if item1 < item2:\n",
    "                return -1\n",
    "            if item1 > item2:\n",
    "                return 1\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    elif item2.startswith('N0'):\n",
    "        return 1\n",
    "    else:\n",
    "        if item1 < item2:\n",
    "            return -1\n",
    "        if item1 > item2:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "def sort_distrib_names(l):\n",
    "    return sorted(l, key=cmp_to_key(compare))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4d3ff8-2b3a-4eb3-b135-178bb33c707e",
   "metadata": {},
   "source": [
    "## Power as heat maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ab94a1-f155-44e6-86cd-a8c59772569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tt_power(df, true_distrib, alter_distrib, alpha):\n",
    "    # find critial value of KS statistic\n",
    "    df_filtred = df[(df['true_dist'] == true_distrib) & (df['alter_dist'] == alter_distrib)]\n",
    "    try:\n",
    "        return 1 - accepted_h0(df_filtred.pvals.values[0], alpha)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def plot_power_matrix_tt(df, label, alpha=0.05, output_to_file=True):\n",
    "    dists = df.alter_dist.unique().tolist()\n",
    "    #dists = sort_distrib_names(dists)\n",
    "    print(dists)\n",
    "    try:\n",
    "        # there is sth broken with n=2500 dim=5\n",
    "        dists.remove('N01xN01xT5xT5xT5')\n",
    "    except:\n",
    "        pass\n",
    "    n_dist = len(dists)\n",
    "    values = np.zeros((n_dist, n_dist))\n",
    "    avg_power = []\n",
    "    signif = []\n",
    "    for id_td, td in enumerate(dists):\n",
    "        for id_ad, ad in enumerate(dists):\n",
    "            values[id_td, id_ad] = get_tt_power(df, td, ad, alpha)\n",
    "            if td != ad:\n",
    "                avg_power.append(values[id_td, id_ad])\n",
    "            else:\n",
    "                signif.append(values[id_td, id_ad])\n",
    "    #print(values)\n",
    "    avg_power = np.nanmean(avg_power)\n",
    "    initial_fig_size = plt.rcParams['figure.figsize']\n",
    "    plt.rcParams['figure.figsize'] = [10, 10]\n",
    "    plt.imshow(values)\n",
    "    # add value in each cell\n",
    "    for id_td, td in enumerate(dists):\n",
    "        for id_ad, ad in enumerate(dists):\n",
    "            val = values[id_ad, id_td] #this is correct, opposite x<->y\n",
    "            if val<0.4:\n",
    "                color='white'\n",
    "            else:\n",
    "                color='black'\n",
    "            plt.text(id_td-0.33, id_ad, f'{val:.2f}', color=color, fontsize=9, fontweight='bold',\n",
    "                    horizontalalignment='left')\n",
    "    plt.xticks(ticks=range(len(dists)), labels=dists, rotation=90, fontsize=13)\n",
    "    plt.yticks(range(len(dists)), labels=dists, fontsize=13)\n",
    "    plt.xlabel('ALTERNATIVE Distribution', fontsize=14)\n",
    "    plt.ylabel('TRUE Distribution', fontsize=14)\n",
    "    plt.title(f'{label} \\n Average Power: {avg_power:.4f}', fontsize=15)\n",
    "    c = plt.colorbar()\n",
    "    plt.clim(0, 1)\n",
    "    if output_to_file:\n",
    "        plt.savefig(f'plots/1sample_discrete_{label.replace(\" \", \"_\")}.pdf', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.rcParams['figure.figsize'] = initial_fig_size\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb1efbc-faaf-47a7-b2d5-6cbb0fe5e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df_with_merge(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    # check if .continualtion file exists\n",
    "    filename_cont = f'{filename}.cont'\n",
    "    if os.path.isfile(filename_cont):\n",
    "        print(f'Continuation file found: {filename_cont}')\n",
    "        df_cont = pd.read_csv(filename_cont)\n",
    "        df = pd.concat([df, df_cont], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7114f7ed-f7d4-4184-935f-3ab964c8369d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Poisson(0.5)', 'Poisson(0.75)', 'Poisson(1)', 'Poisson(1.25)', 'Poisson(1.5)', 'Poisson(2)', 'Poisson(5)', 'Binomial(100, 0.3)', 'Binomial(100, 0.5)', 'Binomial(100, 0.7)', 'Binomial(1000, 0.3)', 'Binomial(1000, 0.5)', 'Binomial(1000, 0.6)', 'Binomial(1000, 0.7)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make one plot to see how it works\n",
    "dim=1\n",
    "n=100\n",
    "alpha=0.05\n",
    "norm='sup'\n",
    "\n",
    "df_tt = read_df_with_merge(f'../results.descrete.jitter/discrete_dim={dim}_n={n}_norm={norm}_method=approximate.csv')\n",
    "plot_power_matrix_tt(df_tt, label=f'TopoTest {dim}D n={n} alpha={alpha} norm={norm}', alpha=alpha,\n",
    "                    output_to_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3e110e1-13bb-46d9-85fb-3b10a895e40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N_0_1', 'N_0_2', 'beta_2_2', 'beta_5_5', 'laplace', 'U_0_1', 'T_3', 'T_5', 'T_10', 'Cauchy', 'Logistic', 'HalfNormal', 'GM_1', 'GM_2', 'GM_3']\n",
      "['N_0_1', 'N_0_2', 'beta_2_2', 'beta_5_5', 'laplace', 'U_0_1', 'T_3', 'T_5', 'T_10', 'Cauchy', 'Logistic', 'HalfNormal', 'GM_1', 'GM_2', 'GM_3']\n",
      "['N_0_1', 'N_0_2', 'beta_2_2', 'beta_5_5', 'laplace', 'U_0_1', 'T_3', 'T_5', 'T_10', 'Cauchy', 'Logistic', 'HalfNormal', 'GM_1', 'GM_2', 'GM_3']\n",
      "['N_0_1', 'N_0_2', 'beta_2_2', 'beta_5_5', 'laplace', 'U_0_1', 'T_3', 'T_5', 'T_10', 'Cauchy', 'Logistic', 'HalfNormal', 'GM_1', 'GM_2', 'GM_3']\n",
      "['N_0_1', 'N_0_2', 'beta_2_2', 'beta_5_5', 'laplace', 'U_0_1', 'T_3', 'T_5', 'T_10', 'Cauchy', 'Logistic', 'HalfNormal', 'GM_1', 'GM_2', 'GM_3']\n",
      "['N01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3', 'T5xT5', 'T10xT10', 'LogisticxLogistic', 'LaplacexLaplace', 'N01xT5', 'GM_1xGM_1', 'N01xGM_1']\n",
      "['N01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3', 'T5xT5', 'T10xT10', 'LogisticxLogistic', 'LaplacexLaplace', 'N01xT5', 'GM_1xGM_1', 'N01xGM_1']\n",
      "['N01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3', 'T5xT5', 'T10xT10', 'LogisticxLogistic', 'LaplacexLaplace', 'N01xT5', 'GM_1xGM_1', 'N01xGM_1']\n",
      "['N01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3', 'T5xT5', 'T10xT10', 'LogisticxLogistic', 'LaplacexLaplace', 'N01xT5', 'GM_1xGM_1', 'N01xGM_1']\n",
      "['N01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3', 'T5xT5', 'T10xT10', 'LogisticxLogistic', 'LaplacexLaplace', 'N01xT5', 'GM_1xGM_1', 'N01xGM_1']\n",
      "Continuation file found: ../results/ks_dim=2_n=2500.csv.cont\n",
      "['N01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3xT3', 'UxUxU', 'B22xB22xB22', 'T5xT5xT5', 'T10xT10xT10', 'LogisticxLogisticxLogistic', 'LaplacexLaplacexLaplace', 'N01xT5xT5', 'N01xN01xT5', 'GM1']\n",
      "['N01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3xT3', 'UxUxU', 'B22xB22xB22', 'T5xT5xT5', 'T10xT10xT10', 'LogisticxLogisticxLogistic', 'LaplacexLaplacexLaplace', 'N01xT5xT5', 'N01xN01xT5', 'GM1']\n",
      "Continuation file found: ../results/ks_dim=3_n=250.csv.cont\n",
      "['N01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3xT3', 'UxUxU', 'B22xB22xB22', 'T5xT5xT5', 'T10xT10xT10', 'LogisticxLogisticxLogistic', 'LaplacexLaplacexLaplace', 'N01xT5xT5', 'N01xN01xT5', 'GM1']\n",
      "['N01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3xT3', 'UxUxU', 'B22xB22xB22', 'T5xT5xT5', 'T10xT10xT10', 'LogisticxLogisticxLogistic', 'LaplacexLaplacexLaplace', 'N01xT5xT5', 'N01xN01xT5', 'GM1']\n",
      "Continuation file found: ../results/ks_dim=3_n=1000.csv.cont\n",
      "['N01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3xT3', 'UxUxU', 'B22xB22xB22', 'T5xT5xT5', 'T10xT10xT10', 'LogisticxLogisticxLogistic', 'LaplacexLaplacexLaplace', 'N01xT5xT5', 'N01xN01xT5', 'GM1']\n",
      "Continuation file found: ../results/ks_dim=3_n=2500.csv.cont\n",
      "['N01xN01xN01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3xT3xT3xT3', 'T5xT5xT5xT5xT5', 'T10xT10xT10xT10xT10', 'N01xT5xT5xT4xT5', 'N01xN01xT5xT5xT5', 'N01xN01xN01xN01xT5', 'LapxLapxLapxLapxLap', 'N01xN01xLapxLapxLap']\n",
      "['N01xN01xN01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3xT3xT3xT3', 'T5xT5xT5xT5xT5', 'T10xT10xT10xT10xT10', 'N01xT5xT5xT4xT5', 'N01xN01xT5xT5xT5', 'N01xN01xN01xN01xT5', 'LapxLapxLapxLapxLap', 'N01xN01xLapxLapxLap']\n",
      "['N01xN01xN01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3xT3xT3xT3', 'T5xT5xT5xT5xT5', 'T10xT10xT10xT10xT10', 'N01xT5xT5xT4xT5', 'N01xN01xT5xT5xT5', 'N01xN01xN01xN01xT5', 'LapxLapxLapxLapxLap', 'N01xN01xLapxLapxLap']\n",
      "['N01xN01xN01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3xT3xT3xT3', 'T5xT5xT5xT5xT5', 'T10xT10xT10xT10xT10', 'N01xT5xT5xT4xT5', 'N01xN01xT5xT5xT5', 'N01xN01xN01xN01xT5', 'LapxLapxLapxLapxLap', 'N01xN01xLapxLapxLap']\n",
      "Continuation file found: ../results/dim=5_n=2500_norm=sup_method=approximate.csv.cont\n",
      "['N01xN01xN01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'MultiGauss0.9', 'T3xT3xT3xT3xT3', 'T5xT5xT5xT5xT5', 'T10xT10xT10xT10xT10', 'N01xT5xT5xT4xT5', 'N01xN01xT5xT5xT5', 'N01xN01xN01xN01xT5', 'LapxLapxLapxLapxLap', 'N01xN01xLapxLapxLap', '-N01xN01xT5xT5xT5']\n",
      "['N01xN01xN01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'T3xT3xT3xT3xT3xT3xT3', 'T5xT5xT5xT5xT5xT5xT5', 'N01xN01xN01xT5xT5xT5xT5', 'N01xN01xN01xN01xLapxLapxLap']\n",
      "['N01xN01xN01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'T3xT3xT3xT3xT3xT3xT3', 'T5xT5xT5xT5xT5xT5xT5', 'N01xN01xN01xT5xT5xT5xT5', 'N01xN01xN01xN01xLapxLapxLap']\n",
      "Continuation file found: ../results/dim=7_n=500_norm=sup_method=approximate.csv.cont\n",
      "['N01xN01xN01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'T3xT3xT3xT3xT3xT3xT3', 'T5xT5xT5xT5xT5xT5xT5', 'N01xN01xN01xT5xT5xT5xT5', 'N01xN01xN01xN01xLapxLapxLap']\n",
      "['N01xN01xN01xN01xN01', 'MultiGauss0.1', 'MultiGauss0.5', 'T3xT3xT3xT3xT3xT3xT3', 'T5xT5xT5xT5xT5xT5xT5', 'N01xN01xN01xT5xT5xT5xT5', 'N01xN01xN01xN01xLapxLapxLap']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dims = [1, 2, 3, 4, 5, 7]\n",
    "ns=[100, 250, 500, 1000, 2500]\n",
    "alpha=0.05\n",
    "norm='sup'\n",
    "for dim in dims:\n",
    "    for n in ns:\n",
    "        try:\n",
    "            df_tt = read_df_with_merge(f'../results/dim={dim}_n={n}_norm={norm}_method=approximate.csv')\n",
    "            plot_power_matrix_tt(df_tt, label=f'TopoTest {dim}D n={n} alpha={alpha} norm={norm}', alpha=alpha,\n",
    "                                output_to_file=True)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            df_ks = read_df_with_merge(f'../results/ks_dim={dim}_n={n}.csv')\n",
    "            plot_power_matrix_ks(df_ks, label=f'KS {dim}D n={n} alpha={alpha}', alpha=alpha,\n",
    "                                output_to_file=True)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7203f2e5-7c4a-4939-84ea-956ad305c53e",
   "metadata": {},
   "source": [
    "## Mean Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fa25a20-570f-4090-8ba2-ae499f54fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_power(df, alpha, mode='tt'):\n",
    "    dists = df.alter_dist.unique()\n",
    "    n_dist = len(dists)\n",
    "    avg_power = []\n",
    "    signif = []\n",
    "    for id_td, td in enumerate(dists):\n",
    "        for id_ad, ad in enumerate(dists):\n",
    "            if mode =='tt':\n",
    "                val = get_tt_power(df, td, ad, alpha)\n",
    "            else:\n",
    "                val = get_ks_power(df, td, ad, alpha)\n",
    "            if td != ad:\n",
    "                avg_power.append(val)\n",
    "            else:\n",
    "                signif.append(val)\n",
    "    return np.nanmean(avg_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20e30b9a-cb49-43f5-ac8b-c82f61f1974b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 504x324 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dims = [1, 2, 3, 5]\n",
    "alpha = 0.05\n",
    "ns=[100, 250, 500, 1000, 2500, 5000]\n",
    "norm = 'sup'\n",
    "\n",
    "plot_ks = True\n",
    "\n",
    "for dim in dims:\n",
    "    power_tt = []\n",
    "    power_ks = []\n",
    "    for n in ns:\n",
    "        try:\n",
    "            df_tt = pd.read_csv(f'../results/dim={dim}_n={n}_norm={norm}_method=approximate.csv')\n",
    "            power_tt.append(mean_power(df_tt, alpha=alpha, mode='tt'))\n",
    "        except:\n",
    "            power_tt.append(np.nan)\n",
    "        try:\n",
    "            df_ks = pd.read_csv(f'../results/ks_dim={dim}_n={n}.csv')\n",
    "            power_ks.append(mean_power(df_ks, alpha=alpha, mode='ks'))\n",
    "        except:\n",
    "            power_ks.append(np.nan)\n",
    "\n",
    "    initial_fig_size = plt.rcParams['figure.figsize']\n",
    "    plt.rcParams['figure.figsize'] = [7, 4.5]\n",
    "    plt.plot(ns, power_tt, 'o-', label='TopoTest')\n",
    "    if plot_ks:\n",
    "        plt.plot(ns, power_ks, 'o-', label='KS')\n",
    "    plt.xlabel('Sample size, n')\n",
    "    plt.ylabel('Average power')\n",
    "    plt.title(f'Average power, dim={dim}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f'plots/1sample_power_n_dim={dim}.pdf', bbox_inches='tight')\n",
    "    plt.rcParams['figure.figsize'] = initial_fig_size\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a7803-2ba9-42c4-ac6b-e0bc4096be7b",
   "metadata": {},
   "source": [
    "# Plot different norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf33aae3-1a53-48be-959c-eaedd94d5dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 504x324 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dims = [2]\n",
    "alpha = 0.05\n",
    "ns=[100, 250, 500, 1000, 2500, 5000]\n",
    "\n",
    "for dim in dims:\n",
    "    power_tt = []\n",
    "    power_ttl1 = []\n",
    "    for n in ns:\n",
    "        # try:\n",
    "            norm='sup'\n",
    "            df_tt = pd.read_csv(f'../results/dim={dim}_n={n}_norm={norm}_method=approximate.csv')\n",
    "            power_tt.append(mean_power(df_tt, alpha=alpha, mode='tt'))\n",
    "        #except:\n",
    "        #    power_tt.append(np.nan)\n",
    "        #try:\n",
    "            norm='l1'\n",
    "            df_l1 = pd.read_csv(f'../results/dim={dim}_n={n}_norm={norm}_method=approximate.csv')\n",
    "            power_ttl1.append(mean_power(df_l1, alpha=alpha, mode='tt'))\n",
    "        #except:\n",
    "        #    power_ttl1.append(np.nan)\n",
    "\n",
    "    initial_fig_size = plt.rcParams['figure.figsize']\n",
    "    plt.rcParams['figure.figsize'] = [7, 4.5]\n",
    "    plt.plot(ns, power_tt, 'o-', label='TopoTest sup')\n",
    "    plt.plot(ns, power_ttl1, 'o-', label='TopoTest l1')\n",
    "    plt.xlabel('Sample size, n')\n",
    "    plt.ylabel('Average power')\n",
    "    plt.title(f'Average power, dim={dim}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f'plots/1sample_norms_power_n_dim={dim}.pdf', bbox_inches='tight')\n",
    "    plt.rcParams['figure.figsize'] = initial_fig_size\n",
    "    plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
