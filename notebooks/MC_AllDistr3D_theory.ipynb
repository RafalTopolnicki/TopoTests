{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ff7211-4c0e-4f43-8361-1493ab65351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "# setting path\n",
    "sys.path.append('../topotests/')\n",
    "sys.path.append('../multiKS/')\n",
    "from topotests import TopoTest\n",
    "from distributions import MultivariateDistribution, GaussianMixture, AbsoluteDistribution\n",
    "from multiKS import multiKS\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "import datetime\n",
    "import sys, getopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1092c67-2055-4648-a9aa-83eee7ed2a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split list l into m chunks\n",
    "# if len(l) is not devisibale by m chunks will have different length\n",
    "def chunks(l, m):\n",
    "    chunks = np.array_split(l, m)\n",
    "    chunks = [chunk for chunk in chunks]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad233911-f874-4aad-ba4d-3c6fa5efc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run KS it in parallell\n",
    "def gof_test_process(subsamples):\n",
    "    ks = []\n",
    "    for sample in subsamples:\n",
    "        ks_out = multiKS(sample, cdf_global)\n",
    "        ks.append(ks_out)\n",
    "    return ks\n",
    "\n",
    "def gof_test(samples, Dstar):\n",
    "    # SET HERE number of cores that will be used to run KS tests in parallel\n",
    "    n_cores = 4 \n",
    "    samples_chunks = chunks(samples, n_cores)\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results_gen = executor.map(gof_test_process, samples_chunks)\n",
    "    results = list(results_gen)   \n",
    "    results_flat = [item for sublist in results for item in sublist]\n",
    "    ks = [d < Dstar for d in results_flat]\n",
    "    ks = np.sum(ks)/len(ks)\n",
    "    return ks, results_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8397f6a4-af1f-4201-9cc6-02605815f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ks(N, rvs, Dstar):\n",
    "    global cdf_global\n",
    "    results = []\n",
    "    result_labels = ['true_distrib', 'alter_distrib', 'method', 'sign_level', 'mc_loops', 'Dstar', 'ks', 'ks_d']\n",
    "    for rv_true in rvs:\n",
    "        print(f'*KS {datetime.datetime.now()} N={N} RV={rv_true.label}')\n",
    "        cdf_global = rv_true.cdf\n",
    "        for rv_alter in rvs:\n",
    "            print(f'*KS {datetime.datetime.now()} N={N} RV={rv_true.label} {rv_alter.label}')\n",
    "            samples = [rv_alter.rvs(N) for i in range(mc_samples)]\n",
    "            ks, dvalues = gof_test(samples, Dstar=Dstar) #Dstar valid for alpha=0.05 N=100, see Justel Table 1\n",
    "            result = [rv_true.label, rv_alter.label, method, significance_level, mc_samples, Dstar, ks, dvalues]\n",
    "            results.append(result)\n",
    "            \n",
    "            # save results to .csv file\n",
    "            results_df = pd.DataFrame(results, columns=result_labels)\n",
    "            results_df.to_csv(f'{outputfile_basename}_N={N}.csv', index=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a512df-191d-4511-a536-9ab3c8e3ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mc(N, rvs):\n",
    "    # generate representation for standard normal distribution\n",
    "    topo_test = TopoTest(n=N, dim=dim, method=method, \n",
    "                         wasserstein_p=wasserstein_p, wasserstein_order=wasserstein_order, ecc_norm=ecc_norm)\n",
    "    results = []\n",
    "    for rv_true in rvs:\n",
    "        print(f'*** {datetime.datetime.now()} N={N} RV={rv_true.label}')\n",
    "        topo_test.fit(rv=rv_true, n_signature=n_signature, n_test=n_test)\n",
    "        # write signature distance matrix\n",
    "        topo_test.save_distance_matrix(outputfile_basename+f'_N={N}_{rv_true.label}_signature_distance_matrix.npy')\n",
    "        topo_test.save_representation(outputfile_basename+f'_N={N}_{rv_true.label}_representation.pickle')\n",
    "        for rv_alter in rvs:\n",
    "            print(f'*** {datetime.datetime.now()} N={N} RV={rv_true.label} {rv_alter.label}')\n",
    "            # generate samples\n",
    "            samples = [rv_alter.rvs(N) for i in range(mc_samples)]\n",
    "            # perform topo tests\n",
    "            topo_out = topo_test.predict(samples, label=rv_alter.label)\n",
    "            # write representation distance matrix\n",
    "            topo_test.save_predict_distance_matrix(outputfile_basename+f'_N={N}_{rv_true.label}-{rv_alter.label}_distance_matrix.npy')\n",
    "            topo_test.save_representation(outputfile_basename+f'_N={N}_{rv_true.label}_representation.pickle')\n",
    "            # aggregate results of topo tests\n",
    "            topo_aggr = {}\n",
    "            for key in topo_out.keys():\n",
    "                topo_aggr[f'topo_{key}'] = np.mean(topo_out[key])\n",
    "            # save thresholds to the csv as well\n",
    "            topo_thres = {}\n",
    "            for key in topo_test.representation_threshold.keys():\n",
    "                topo_thres[f'thres_{key}'] = topo_test.representation_threshold[key]\n",
    "\n",
    "            # the is really no point in determining labels in each loop as they are constant, but keep it as it is for simplicity\n",
    "            result_labels = ['true_distrib', 'alter_distrib', 'method', 'sign_level', 'wasserstein_p', 'wasserstein_order', 'ecc_norm',\n",
    "                 'mc_loops', 'n_signature', 'n_test', *topo_thres.keys(), *topo_aggr.keys()]\n",
    "\n",
    "            result = [rv_true.label, rv_alter.label, method, significance_level, wasserstein_p, wasserstein_order, ecc_norm,\n",
    "                      mc_samples, n_signature, n_test, *topo_thres.values(), *topo_aggr.values()]\n",
    "            results.append(result)\n",
    "            \n",
    "            # save results to .csv file\n",
    "            results_df = pd.DataFrame([result], columns=result_labels)\n",
    "            #results_df.reset_index(drop=True, inplace=True)\n",
    "            try:\n",
    "                df_old = pd.read_csv(f'{outputfile_basename}_n={N}_M={n_signature}_m={n_test}.csv')\n",
    "                #df_old.reset_index(drop=True, inplace=True)\n",
    "                results_df = pd.concat([df_old, results_df], axis=0, ignore_index=True)\n",
    "            except:\n",
    "                pass\n",
    "            results_df.to_csv(f'{outputfile_basename}_n={N}_M={n_signature}_m={n_test}.csv', index=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e573aed6-e42e-4e8e-aab6-010a02d59fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs = [MultivariateDistribution([st.norm(), st.norm(), st.norm()], label='N01xN01xN01'),\n",
    "       MultivariateDistribution([st.t(df=3), st.t(df=3), st.t(df=3)], label='T3xT3xT3'),\n",
    "       MultivariateDistribution([st.uniform(), st.uniform(), st.uniform()], label='UxUxU'),\n",
    "       MultivariateDistribution([st.beta(2,2), st.beta(2,2), st.beta(2,2)], label='B22xB22xB22')\n",
    "       # MultivariateDistribution([st.t(df=5), st.t(df=5), st.t(df=5)], label='T5xT5xT5'),\n",
    "       # MultivariateDistribution([st.t(df=10), st.t(df=10), st.t(df=10)], label='T10xT10xT10'),\n",
    "       # MultivariateDistribution([st.logistic(), st.logistic(), st.logistic()], label='LogisticxLogisticxLogistic'),\n",
    "       # MultivariateDistribution([st.laplace(), st.laplace(), st.laplace()], label='LaplacexLaplacexLaplace'),\n",
    "       # MultivariateDistribution([st.norm(), st.t(df=5), st.t(df=5)], label='N01xT5xT5'),\n",
    "       # MultivariateDistribution([st.norm(), st.norm(), st.t(df=5)], label='N01xN01xT5'),\n",
    "       # MultivariateDistribution([GaussianMixture([-1, 1, 0], [1, 1, 1], [0.33, 0.33, 0.34]),\n",
    "       #                          GaussianMixture([-1, 1, 0], [1, 1, 1], [0.33, 0.33, 0.34]),\n",
    "       #                          GaussianMixture([-1, 1, 0], [1, 1, 2], [0.33, 0.33, 0.34])], label='GM1')\n",
    "                                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd52d611-9d43-435e-8d27-a9bafca23f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "argv = sys.argv[1:]\n",
    "method = None\n",
    "ecc_norm = None\n",
    "n_signature = None\n",
    "n_test = None\n",
    "mc_samples = None\n",
    "n_sample = None \n",
    "\n",
    "try:\n",
    "    opts, args = getopt.getopt(argv,\"t:M:n:m:C:e:\")\n",
    "except getopt.GetoptError:\n",
    "    print('MC_AllDistr3D.py -t -M -n -m -C -e')\n",
    "    sys.exit(2)\n",
    "for opt, arg in opts:\n",
    "    if opt in ('-t'):\n",
    "        method = arg\n",
    "    if opt in ('-e'):\n",
    "        ecc_norm = arg\n",
    "    if opt in ('-M'):\n",
    "        n_signature = int(arg)\n",
    "    if opt in ('-m'):\n",
    "        n_test = int(arg)\n",
    "    if opt in ('-n'):\n",
    "        n_sample = int(arg)\n",
    "    if opt in ('-C'):\n",
    "        mc_samples = int(arg)\n",
    "\n",
    "if method == None:\n",
    "    raise ValueError('-t parameter missing')\n",
    "if n_signature == None:\n",
    "    raise ValueError('-M parameter missing')\n",
    "if n_test == None:\n",
    "    raise ValueError('-m parameter missing')\n",
    "if mc_samples == None:\n",
    "    raise ValueError('-C parameter missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc1983b-0f97-4436-9705-95f065cc85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method='ecc'\n",
    "# ecc_norm='sup'\n",
    "# n_signature=25\n",
    "# n_test=25\n",
    "# mc_samples=100\n",
    "# n_sample=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65c8ebc8-6a2f-47b1-962e-f3eb6cc358ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random numbers generator seed to have reproducibale results\n",
    "np.random.seed(1)\n",
    "\n",
    "cdf_global = None\n",
    "\n",
    "dim = 3\n",
    "significance_level = 0.05\n",
    "wasserstein_p=1\n",
    "wasserstein_order=1\n",
    "\n",
    "dirname = f'results.{dim}d_theory'\n",
    "\n",
    "if method not in ['ecc', 'ecc-exact', 'ks']:\n",
    "    outputfile_basename = f'{dirname}/{method}_{wasserstein_p}_{wasserstein_order}'\n",
    "elif method == 'ecc':\n",
    "    outputfile_basename = f'{dirname}/{method}_{ecc_norm}'\n",
    "elif method == 'ks':\n",
    "    outputfile_basename = f'{dirname}/{method}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1963f33a-763a-4d3a-9636-b4d3c8d7ecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 2022-05-03 17:54:08.920794 N=100 RV=N01xN01xN01\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mks\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_mc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     results \u001b[38;5;241m=\u001b[39m run_ks(N\u001b[38;5;241m=\u001b[39mn_sample, rvs\u001b[38;5;241m=\u001b[39mrvs, Dstar\u001b[38;5;241m=\u001b[39mDstar)\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mrun_mc\u001b[0;34m(N, rvs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rv_true \u001b[38;5;129;01min\u001b[39;00m rvs:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*** \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m N=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m RV=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrv_true\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mtopo_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrv_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_signature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# write signature distance matrix\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     topo_test\u001b[38;5;241m.\u001b[39msave_distance_matrix(outputfile_basename\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_N=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrv_true\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_signature_distance_matrix.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/WORK/IMPAN/Distributions/topotests/notebooks/../topotests/topotests.py:77\u001b[0m, in \u001b[0;36mTopoTest.fit\u001b[0;34m(self, rv, n_signature, n_test)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation_signature[::representation_test_skip]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 77\u001b[0m     dmin, dmean, dmax, dq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation_threshold \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mquantile(dmin, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignificance_level),\n\u001b[1;32m     79\u001b[0m                                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mquantile(dmean, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignificance_level),\n\u001b[1;32m     80\u001b[0m                                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mquantile(dmax, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignificance_level),\n\u001b[1;32m     81\u001b[0m                                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantile\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mquantile(dq, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignificance_level)\n\u001b[1;32m     82\u001b[0m                                      }\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/WORK/IMPAN/Distributions/topotests/notebooks/../topotests/topotests.py:89\u001b[0m, in \u001b[0;36mTopoTest.aggregate_distances\u001b[0;34m(self, distance_matrix)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate_distances\u001b[39m(\u001b[38;5;28mself\u001b[39m, distance_matrix):\n\u001b[0;32m---> 89\u001b[0m     dmean \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     dmin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(distance_matrix, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     91\u001b[0m     dmax \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(distance_matrix, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/WORK/IMPAN/Distributions/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3471\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3472\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/WORK/IMPAN/Distributions/venv/lib/python3.8/site-packages/numpy/core/_methods.py:167\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    163\u001b[0m arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[1;32m    165\u001b[0m is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m rcount \u001b[38;5;241m=\u001b[39m \u001b[43m_count_reduce_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m umr_any(rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    169\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of empty slice.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/WORK/IMPAN/Distributions/venv/lib/python3.8/site-packages/numpy/core/_methods.py:76\u001b[0m, in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis, keepdims, where)\u001b[0m\n\u001b[1;32m     74\u001b[0m     items \u001b[38;5;241m=\u001b[39m nt\u001b[38;5;241m.\u001b[39mintp(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis:\n\u001b[0;32m---> 76\u001b[0m         items \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mshape[\u001b[43mmu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_axis_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# TODO: Optimize case when `where` is broadcast along a non-reduction\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# axis and full sum is more excessive than needed.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# guarded to protect circular imports\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstride_tricks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m broadcast_to\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "if method != 'ks':\n",
    "    results = run_mc(N=n_sample, rvs=rvs)\n",
    "else:\n",
    "    results = run_ks(N=n_sample, rvs=rvs, Dstar=Dstar)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
