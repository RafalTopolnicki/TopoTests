{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ff7211-4c0e-4f43-8361-1493ab65351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "# setting path\n",
    "sys.path.append('../topotests/')\n",
    "sys.path.append('../multiKS/')\n",
    "from topotests import TopoTest\n",
    "from distributions import MultivariateDistribution, GaussianMixture, AbsoluteDistribution\n",
    "from multiKS import multiKS\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "import datetime\n",
    "import sys, getopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1092c67-2055-4648-a9aa-83eee7ed2a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split list l into m chunks\n",
    "# if len(l) is not devisibale by m chunks will have different length\n",
    "def chunks(l, m):\n",
    "    chunks = np.array_split(l, m)\n",
    "    chunks = [chunk for chunk in chunks]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad233911-f874-4aad-ba4d-3c6fa5efc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run KS it in parallell\n",
    "def gof_test_process(subsamples):\n",
    "    ks = []\n",
    "    for sample in subsamples:\n",
    "        ks_out = multiKS(sample, cdf_global)\n",
    "        ks.append(ks_out)\n",
    "    return ks\n",
    "\n",
    "def gof_test(samples, Dstar):\n",
    "    # SET HERE number of cores that will be used to run KS tests in parallel\n",
    "    n_cores = 4 \n",
    "    samples_chunks = chunks(samples, n_cores)\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results_gen = executor.map(gof_test_process, samples_chunks)\n",
    "    results = list(results_gen)   \n",
    "    results_flat = [item for sublist in results for item in sublist]\n",
    "    ks = [d < Dstar for d in results_flat]\n",
    "    ks = np.sum(ks)/len(ks)\n",
    "    return ks, results_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8397f6a4-af1f-4201-9cc6-02605815f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ks(N, rvs, Dstar):\n",
    "    global cdf_global\n",
    "    results = []\n",
    "    result_labels = ['true_distrib', 'alter_distrib', 'method', 'sign_level', 'mc_loops', 'Dstar', 'ks', 'ks_d']\n",
    "    for rv_true in rvs:\n",
    "        print(f'*KS {datetime.datetime.now()} N={N} RV={rv_true.label}')\n",
    "        cdf_global = rv_true.cdf\n",
    "        for rv_alter in rvs:\n",
    "            print(f'*KS {datetime.datetime.now()} N={N} RV={rv_true.label} {rv_alter.label}')\n",
    "            samples = [rv_alter.rvs(N) for i in range(mc_samples)]\n",
    "            ks, dvalues = gof_test(samples, Dstar=Dstar) #Dstar valid for alpha=0.05 N=100, see Justel Table 1\n",
    "            result = [rv_true.label, rv_alter.label, method, significance_level, mc_samples, Dstar, ks, dvalues]\n",
    "            results.append(result)\n",
    "            \n",
    "            # save results to .csv file\n",
    "            results_df = pd.DataFrame(results, columns=result_labels)\n",
    "            results_df.to_csv(f'{outputfile_basename}_N={N}.csv')\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1a512df-191d-4511-a536-9ab3c8e3ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mc(N, rvs):\n",
    "    # generate representation for standard normal distribution\n",
    "    topo_test = TopoTest(n=N, dim=dim, method=method, \n",
    "                         wasserstein_p=wasserstein_p, wasserstein_order=wasserstein_order, ecc_norm=ecc_norm)\n",
    "    results = []\n",
    "    for rv_true in rvs:\n",
    "        print(f'*** {datetime.datetime.now()} N={N} RV={rv_true.label}')\n",
    "        topo_test.fit(rv=rv_true, n_signature=n_signature, n_test=n_test)\n",
    "        # write signature distance matrix\n",
    "        topo_test.save_distance_matrix(outputfile_basename+f'_N={N}_{rv_true.label}_signature_distance_matrix.npy')\n",
    "        for rv_alter in rvs:\n",
    "            print(f'*** {datetime.datetime.now()} N={N} RV={rv_true.label} {rv_alter.label}')\n",
    "            # generate samples\n",
    "            samples = [rv_alter.rvs(N) for i in range(mc_samples)]\n",
    "            # perform topo tests\n",
    "            topo_out = topo_test.predict(samples)\n",
    "            # write representation distance matrix\n",
    "            topo_test.save_predict_distance_matrix(outputfile_basename+f'_N={N}_{rv_true.label}-{rv_alter.label}_distance_matrix.npy')\n",
    "            # aggregate results of topo tests\n",
    "            topo_aggr = {}\n",
    "            for key in topo_out.keys():\n",
    "                topo_aggr[f'topo_{key}'] = np.mean(topo_out[key])\n",
    "            # save thresholds to the csv as well\n",
    "            topo_thres = {}\n",
    "            for key in topo_test.representation_threshold.keys():\n",
    "                topo_thres[f'thres_{key}'] = topo_test.representation_threshold[key]\n",
    "\n",
    "            # the is really no point in determining labels in each loop as they are constant, but keep it as it is for simplicity\n",
    "            result_labels = ['true_distrib', 'alter_distrib', 'method', 'sign_level', 'wasserstein_p', 'wasserstein_order', 'ecc_norm',\n",
    "                 'mc_loops', 'n_signature', 'n_test', *topo_thres.keys(), *topo_aggr.keys()]\n",
    "\n",
    "            result = [rv_true.label, rv_alter.label, method, significance_level, wasserstein_p, wasserstein_order, ecc_norm,\n",
    "                      mc_samples, n_signature, n_test, *topo_thres.values(), *topo_aggr.values()]\n",
    "            results.append(result)\n",
    "            \n",
    "            # save results to .csv file\n",
    "            results_df = pd.DataFrame(results, columns=result_labels)\n",
    "            results_df.to_csv(f'{outputfile_basename}_N={N}.csv')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e573aed6-e42e-4e8e-aab6-010a02d59fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs = [MultivariateDistribution([st.norm(), st.norm(), st.norm()], label='N01xN01xN01'),\n",
    "       MultivariateDistribution([st.t(df=3), st.t(df=3), st.t(df=3)], label='T3xT3xT3'),\n",
    "       MultivariateDistribution([st.t(df=5), st.t(df=5), st.t(df=5)], label='T5xT5xT5'),\n",
    "       MultivariateDistribution([st.t(df=10), st.t(df=10), st.t(df=10)], label='T10xT10xT10'),\n",
    "       MultivariateDistribution([st.logistic(), st.logistic(), st.logistic()], label='LogisticxLogisticxLogistic'),\n",
    "       MultivariateDistribution([st.laplace(), st.laplace(), st.laplace()], label='LaplacexLaplacexLaplace'),\n",
    "       MultivariateDistribution([st.norm(), st.t(df=5), st.t(df=5)], label='N01xT5xT5'),\n",
    "       MultivariateDistribution([st.norm(), st.norm(), st.t(df=5)], label='N01xN01xT5'),\n",
    "       MultivariateDistribution([GaussianMixture([-1, 1, 0], [1, 1, 1], [0.33, 0.33, 0.34]),\n",
    "                                GaussianMixture([-1, 1, 0], [1, 1, 1], [0.33, 0.33, 0.34]),\n",
    "                                GaussianMixture([-1, 1, 0], [1, 1, 2], [0.33, 0.33, 0.34])], label='GM1')\n",
    "                                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e39451-a6de-453d-9d96-2a649ed32cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "argv = sys.argv[1:]\n",
    "method = None\n",
    "ecc_norm = None\n",
    "try:\n",
    "    opts, args = getopt.getopt(argv,\"m:n:\")\n",
    "except getopt.GetoptError:\n",
    "    print('MC_AllDistr3D.py -m <method>')\n",
    "    sys.exit(2)\n",
    "for opt, arg in opts:\n",
    "    if opt in ('-m'):\n",
    "        method = arg\n",
    "    if opt in ('-n'):\n",
    "        ecc_norm = arg\n",
    "\n",
    "if method == None:\n",
    "    raise ValueError('-m parameter missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b46cf71-c101-424b-a335-9c22f3157243",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'ks'\n",
    "ecc_norm = 'l1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65c8ebc8-6a2f-47b1-962e-f3eb6cc358ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random numbers generator seed to have reproducibale results\n",
    "np.random.seed(1)\n",
    "\n",
    "cdf_global = None\n",
    "\n",
    "# set simulation parameters\n",
    "# Ns = [20, 50, 100, 200]\n",
    "# Dstars = [0.151494, 0.110596, 0.086214, 0.064754] # values obtained from separate KS simulations\n",
    "# mc_samples = 250\n",
    "# n_signature = n_test = 750\n",
    "\n",
    "Ns = [20]\n",
    "Dstars = [0.151494]\n",
    "mc_samples = 10\n",
    "n_signature = n_test = 10\n",
    "\n",
    "dim = 3\n",
    "significance_level = 0.05\n",
    "wasserstein_p=1\n",
    "wasserstein_order=1\n",
    "ecc_norm = 'l1'\n",
    "\n",
    "dirname = f'temp_results.{dim}d'\n",
    "\n",
    "if method not in ['ecc', 'ks']:\n",
    "    outputfile_basename = f'{dirname}/{method}_{wasserstein_p}_{wasserstein_order}'\n",
    "elif method == 'ecc':\n",
    "    outputfile_basename = f'{dirname}/{method}_{ecc_norm}'\n",
    "elif method == 'ks':\n",
    "    outputfile_basename = f'{dirname}/{method}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963f33a-763a-4d3a-9636-b4d3c8d7ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if method != 'ks':\n",
    "    for N in Ns:\n",
    "        results = run_mc(N=N, rvs=rvs)\n",
    "else:\n",
    "    for N, Dstar in zip(Ns, Dstars):\n",
    "        results = run_ks(N=N, rvs=rvs, Dstar=Dstar)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
