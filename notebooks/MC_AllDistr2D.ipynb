{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ff7211-4c0e-4f43-8361-1493ab65351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "# setting path\n",
    "sys.path.append('../topotests/')\n",
    "sys.path.append('../multiKS/')\n",
    "from topotests import TopoTest\n",
    "from distributions import MultivariateDistribution, GaussianMixture, AbsoluteDistribution\n",
    "from multiKS import multiKS\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "import datetime\n",
    "import sys, getopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1092c67-2055-4648-a9aa-83eee7ed2a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split list l into m chunks\n",
    "# if len(l) is not devisibale by m chunks will have different length\n",
    "def chunks(l, m):\n",
    "    chunks = np.array_split(l, m)\n",
    "    chunks = [chunk for chunk in chunks]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad233911-f874-4aad-ba4d-3c6fa5efc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run KS it in parallell\n",
    "def gof_test_process(subsamples):\n",
    "    ks = []\n",
    "    for sample in subsamples:\n",
    "        ks_out = multiKS(sample, cdf_global)\n",
    "        ks.append(ks_out)\n",
    "    return ks\n",
    "\n",
    "def gof_test(samples, Dstar):\n",
    "    n_cores = 4 \n",
    "    samples_chunks = chunks(samples, n_cores)\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results_gen = executor.map(gof_test_process, samples_chunks)\n",
    "    results = list(results_gen)   \n",
    "    results_flat = [item for sublist in results for item in sublist]\n",
    "    ks = [d < Dstar for d in results_flat]\n",
    "    ks = np.sum(ks)/len(ks)\n",
    "    return ks, results_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1a512df-191d-4511-a536-9ab3c8e3ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mc(N, rvs):\n",
    "    global cdf_global\n",
    "    # generate representation for standard normal distribution\n",
    "    topo_test = TopoTest(n=N, dim=dim, method=method, \n",
    "                         wasserstein_p=wasserstein_p, wasserstein_order=wasserstein_order)\n",
    "    \n",
    "    results = []\n",
    "    result_labels = ['true_distrib', 'alter_distrib', 'method', 'sign_level', 'wasserstein_p', 'wasserstein_order',\n",
    "                 'mc_loops', 'n_signature', 'n_test', \n",
    "                 'topo_min', 'topo_mean', 'topo_max', 'topo_quantile',\n",
    "                 'ks', 'ks_d']\n",
    "    \n",
    "    for rv_true in rvs:\n",
    "        print(f'*** {datetime.datetime.now()} N={N} RV={rv_true.label}')\n",
    "        topo_test.fit(rv=rv_true, n_signature=n_signature, n_test=n_test)\n",
    "        # write signature distance matrix\n",
    "        topo_test.save_distance_matrix(outputfile_basename+f'_N={N}_{rv_true.label}_signature_distance_matrix.npy')\n",
    "        for rv_alter in rvs:\n",
    "            print(f'*** {datetime.datetime.now()} N={N} RV={rv_true.label} {rv_alter.label}')\n",
    "            # generate samples\n",
    "            samples = [rv_alter.rvs(N) for i in range(mc_samples)]\n",
    "            # perform topo tests\n",
    "            topo_out = topo_test.predict(samples)\n",
    "            # write representation distance matrix\n",
    "            topo_test.save_predict_distance_matrix(outputfile_basename+f'_N={N}_{rv_true.label}-{rv_alter.label}_distance_matrix.npy')\n",
    "            # aggregate results of topo tests\n",
    "            topo_min = np.mean(topo_out.min)\n",
    "            topo_mean = np.mean(topo_out.mean)\n",
    "            topo_max = np.mean(topo_out.max)\n",
    "            topo_quantile = np.mean(topo_out.quantile)\n",
    "            # collect results of KS test\n",
    "            cdf_global = rv_true.cdf\n",
    "            ks, dvalues = gof_test(samples, Dstar=0.1675) #Dstar valid for alpha=0.05 N=100, see Justel Table 1 \n",
    "            #ks, dvalues = [], []\n",
    "            # collect results of topo tests and goodness of fit (gof) tests\n",
    "            result = [rv_true.label, rv_alter.label, method, significance_level, wasserstein_p, wasserstein_order, \n",
    "                      mc_samples, n_signature, n_test, \n",
    "                      topo_min, topo_mean, topo_max, topo_quantile,\n",
    "                      ks, dvalues]\n",
    "            results.append(result)\n",
    "            # save results to .csv file\n",
    "            results_df = pd.DataFrame(results, columns=result_labels)\n",
    "            results_df.to_csv(f'{outputfile_basename}_N={N}.csv')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e573aed6-e42e-4e8e-aab6-010a02d59fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs = [MultivariateDistribution([st.norm(), st.norm()], label='N01xN01'),\n",
    "       MultivariateDistribution([st.t(df=3), st.t(df=3)], label='T3xT3'),\n",
    "       MultivariateDistribution([st.t(df=5), st.t(df=5)], label='T5xT5'),\n",
    "       MultivariateDistribution([st.t(df=10), st.t(df=10)], label='T10xT10'),\n",
    "       MultivariateDistribution([st.logistic(), st.logistic()], label='LogisticxLogistic'),\n",
    "       MultivariateDistribution([st.laplace(), st.laplace()], label='LaplacexLaplace'),\n",
    "       MultivariateDistribution([st.norm(), st.t(df=5)], label='N01xT5'),\n",
    "       MultivariateDistribution([GaussianMixture([-1, 1], [1, 1], [0.5, 0.5]),\n",
    "                                GaussianMixture([-1, 1], [1, 1], [0.5, 0.5])], label='GM_1xGM_1'),\n",
    "       MultivariateDistribution([st.norm(),\n",
    "                                GaussianMixture([-1, 1], [1, 1], [0.5, 0.5])], label='N01xGM_1')      \n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e39451-a6de-453d-9d96-2a649ed32cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "argv = sys.argv[1:]\n",
    "method = None\n",
    "try:\n",
    "    opts, args = getopt.getopt(argv,\"m:\")\n",
    "except getopt.GetoptError:\n",
    "    print('MC_AllDistr2D.py -m <method>')\n",
    "    sys.exit(2)\n",
    "for opt, arg in opts:\n",
    "    if opt in ('-m'):\n",
    "        method = arg\n",
    "\n",
    "if method == None:\n",
    "    raise ValueError('-m parameter missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65c8ebc8-6a2f-47b1-962e-f3eb6cc358ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random numbers generator seed to have reproducibale results\n",
    "np.random.seed(1)\n",
    "\n",
    "cdf_global = None\n",
    "\n",
    "# set simulation parameters\n",
    "Ns = [25, 50, 100, 200, 300]\n",
    "mc_samples = 250\n",
    "n_signature = n_test = 750\n",
    "\n",
    "dim = 2\n",
    "significance_level = 0.05\n",
    "wasserstein_p=1\n",
    "wasserstein_order=1\n",
    "\n",
    "outputfile_basename = f'results.{dim}d/{method}_{wasserstein_p}_{wasserstein_order}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1963f33a-763a-4d3a-9636-b4d3c8d7ecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 2022-02-27 12:10:38.823459 N=15 RV=N01xN01\n",
      "*** 2022-02-27 12:10:39.782121 N=15 RV=N01xN01 N01xN01\n",
      "Sample done\n",
      "X.1\n",
      "<generator object _chain_from_iterable_of_lists at 0x7f0f67fa6a50>\n",
      "*** 2022-02-27 12:10:40.383490 N=15 RV=N01xN01 T3xT3\n",
      "Sample done\n",
      "X.1\n",
      "<generator object _chain_from_iterable_of_lists at 0x7f0f67fa6ba0>\n",
      "*** 2022-02-27 12:10:40.966753 N=15 RV=N01xN01 T5xT5\n",
      "Sample done\n",
      "X.1\n",
      "<generator object _chain_from_iterable_of_lists at 0x7f0f67fa6ba0>\n",
      "*** 2022-02-27 12:10:41.537695 N=15 RV=N01xN01 T10xT10\n",
      "Sample done\n",
      "X.1\n",
      "<generator object _chain_from_iterable_of_lists at 0x7f0f67fa6b30>\n",
      "*** 2022-02-27 12:10:42.093151 N=15 RV=N01xN01 LogisticxLogistic\n",
      "Sample done\n",
      "X.1\n",
      "<generator object _chain_from_iterable_of_lists at 0x7f0f67fa6b30>\n",
      "*** 2022-02-27 12:10:42.659406 N=15 RV=N01xN01 LaplacexLaplace\n",
      "Sample done\n",
      "X.1\n",
      "<generator object _chain_from_iterable_of_lists at 0x7f0f67fa6ba0>\n",
      "*** 2022-02-27 12:10:43.254755 N=15 RV=N01xN01 N01xT5\n",
      "Sample done\n",
      "X.1\n",
      "<generator object _chain_from_iterable_of_lists at 0x7f0f67fa6ba0>\n",
      "*** 2022-02-27 12:10:43.870096 N=15 RV=N01xN01 GM_1xGM_1\n",
      "Sample done\n",
      "X.1\n",
      "<generator object _chain_from_iterable_of_lists at 0x7f0f67fa6ba0>\n",
      "*** 2022-02-27 12:10:44.518423 N=15 RV=N01xN01 N01xGM_1\n",
      "Sample done\n",
      "X.1\n",
      "<generator object _chain_from_iterable_of_lists at 0x7f0f67fa6b30>\n",
      "*** 2022-02-27 12:10:45.123689 N=15 RV=T3xT3\n",
      "*** 2022-02-27 12:10:46.196044 N=15 RV=T3xT3 N01xN01\n",
      "Sample done\n",
      "X.1\n",
      "<generator object _chain_from_iterable_of_lists at 0x7f0f67fa6b30>\n",
      "*** 2022-02-27 12:10:46.819253 N=15 RV=T3xT3 T3xT3\n",
      "Sample done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-85:\n",
      "Process ForkProcess-86:\n",
      "Process ForkProcess-87:\n",
      "Process ForkProcess-88:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m N \u001b[38;5;129;01min\u001b[39;00m Ns:\n\u001b[0;32m----> 2\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_mc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mrun_mc\u001b[0;34m(N, rvs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# collect results of KS test\u001b[39;00m\n\u001b[1;32m     32\u001b[0m cdf_global \u001b[38;5;241m=\u001b[39m rv_true\u001b[38;5;241m.\u001b[39mcdf\n\u001b[0;32m---> 33\u001b[0m ks, dvalues \u001b[38;5;241m=\u001b[39m \u001b[43mgof_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDstar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1675\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Dstar valid for alpha=0.05 N=100, see Justel Table 1 \u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#ks, dvalues = [], []\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# collect results of topo tests and goodness of fit (gof) tests\u001b[39;00m\n\u001b[1;32m     36\u001b[0m result \u001b[38;5;241m=\u001b[39m [rv_true\u001b[38;5;241m.\u001b[39mlabel, rv_alter\u001b[38;5;241m.\u001b[39mlabel, method, significance_level, wasserstein_p, wasserstein_order, \n\u001b[1;32m     37\u001b[0m           mc_samples, n_signature, n_test, \n\u001b[1;32m     38\u001b[0m           topo_min, topo_mean, topo_max, topo_quantile,\n\u001b[1;32m     39\u001b[0m           ks, dvalues]\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mgof_test\u001b[0;34m(samples, Dstar)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample done\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m---> 14\u001b[0m     results_gen \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mmap(gof_test_process, samples_chunks)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX.1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_gen)\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:644\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/process.py:686\u001b[0m, in \u001b[0;36mProcessPoolExecutor.shutdown\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue_management_thread_wakeup\u001b[38;5;241m.\u001b[39mwakeup()\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m--> 686\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_queue_management_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;66;03m# objects that use file descriptors.\u001b[39;00m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue_management_thread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:1011\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:1027\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# already determined that the C code is done\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_stopped\n\u001b[0;32m-> 1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1028\u001b[0m     lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 97, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "for N in Ns:\n",
    "    results = run_mc(N=N, rvs=rvs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
